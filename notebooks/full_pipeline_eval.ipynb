{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN0OGAG52BFS1VGbh/MFdit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShouryaBatra/psbs-research-project/blob/main/notebooks/full_pipeline_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOEHcjyhrvWH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Store token in env variable (more secure than plain text)\n",
        "os.environ['GITHUB_TOKEN'] = \"yourGithubToken\"\n",
        "\n",
        "# Use it to clone\n",
        "!git clone https://$GITHUB_TOKEN@github.com/ShouryaBatra/psbs-research-project.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd psbs-research-project/"
      ],
      "metadata": {
        "id": "iqyOuiCKsVvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r psbs-research-project/leak_eval/requirements.txt"
      ],
      "metadata": {
        "id": "BDp7jLLBst8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt env variable\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"yourOpenAIKey\""
      ],
      "metadata": {
        "id": "rMYJuWmOtzIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create results directory in main directory\n",
        "\n",
        "!mkdir -p results"
      ],
      "metadata": {
        "id": "g39q71_st5Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check gpu\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8M6aiebbuIbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clear any cached downloads\n",
        "!rm -rf ~/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B"
      ],
      "metadata": {
        "id": "76i3vwHRuLk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install model\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "\n",
        "# Set environment to avoid any caching issues\n",
        "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
        "\n",
        "# Download fresh copy\n",
        "print(\"Downloading Qwen2.5-1.5B model...\")\n",
        "snapshot_download(\n",
        "    repo_id=\"Qwen/Qwen2.5-1.5B\",\n",
        "    local_dir=\"qwen2.5-1.5b\",\n",
        "    resume_download=False,  # Don't resume corrupted downloads\n",
        "    local_files_only=False,  # Download from internet\n",
        "    force_download=True      # Force fresh download\n",
        ")\n",
        "print(\"Download completed!\")"
      ],
      "metadata": {
        "id": "PIjw8E9JuRs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the model files are present and valid\n",
        "!ls -la qwen2.5-1.5b/\n",
        "!ls -la qwen2.5-1.5b/*.safetensors"
      ],
      "metadata": {
        "id": "zMy1cjdPuZHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy over prompts folder into main directory\n",
        "\n",
        "!cp -r psbs-research-project/prompts ."
      ],
      "metadata": {
        "id": "9hIrigfauvk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install airgapagent-r benchmarks\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "\n",
        "# Create datasets directory if it doesn't exist\n",
        "os.makedirs(\"psbs-research-project/leak_eval/datasets\", exist_ok=True)\n",
        "\n",
        "# Download the airgapagent datasets from Hugging Face\n",
        "snapshot_download(\n",
        "    repo_id=\"parameterlab/leaky_thoughts\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"./psbs-research-project/leak_eval/datasets\",\n",
        "    ignore_patterns=[\"*.arrow\", \"*.lock\"]  # Optional: skip unnecessary files\n",
        ")"
      ],
      "metadata": {
        "id": "hQtdR-cUvPQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create airgapagent sample dataset of 15\n",
        "!python psbs-research-project/leak_eval/scripts/create_sample_dataset.py \\\n",
        "--input_file psbs-research-project/leak_eval/datasets/airgapagent-r-small.json \\\n",
        "--output_file psbs-research-project/leak_eval/datasets/airgapagent-r-sample-15.json \\\n",
        "--sample_size 15 \\\n",
        "--seed 42"
      ],
      "metadata": {
        "id": "DcUmAPBMw-wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create airgapagent sample dataset of 100\n",
        "!python psbs-research-project/leak_eval/scripts/create_sample_dataset.py \\\n",
        "--input_file psbs-research-project/leak_eval/datasets/airgapagent-r-small.json \\\n",
        "--output_file psbs-research-project/leak_eval/datasets/airgapagent-r-sample-100.json \\\n",
        "--sample_size 100 \\\n",
        "--seed 42"
      ],
      "metadata": {
        "id": "tvvt-d6WxRbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy over more files needed\n",
        "\n",
        "!cp psbs-research-project/leak_eval/approp_matrix.csv .\n",
        "!cp psbs-research-project/leak_eval/cp_eval_utils.py .\n",
        "!cp psbs-research-project/leak_eval/generate_utils.py ."
      ],
      "metadata": {
        "id": "7mn_yl3U1LHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on airgapagent-r-sample-15 (15 prompts)\n",
        "# can also change to test on airgapagent-r-sample-100 (don't do this though, that costs a lot of memory)\n",
        "\n",
        "!python psbs-research-project/leak_eval/eval_cp.py \\\n",
        "--model qwen2.5-1.5b \\\n",
        "--input_file psbs-research-project/leak_eval/datasets/airgapagent-r-sample-15.json \\\n",
        "--output_file results/tiny_test_cot.json \\\n",
        "--gpt_eval \\\n",
        "--prompt_type cot_explicit_unk \\\n",
        "--max_tokens 200 \\\n",
        "--temperature 0.1"
      ],
      "metadata": {
        "id": "2J1lV3HsxlAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9788d0a6"
      },
      "source": [
        "# get summary block from new results and print it\n",
        "\n",
        "import json\n",
        "\n",
        "file_path = 'results/tiny_test_cot.json'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "summary_block = data.get('summary')\n",
        "\n",
        "if summary_block:\n",
        "    print(json.dumps(summary_block, indent=2))\n",
        "else:\n",
        "    print(f\"Could not find 'summary' block in {file_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}